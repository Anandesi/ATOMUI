from abc import abstractmethod
from dataclasses import dataclass
from typing import Any, Dict, List, Optional, Union
import numpy as np
from bertopic import BERTopic
from sklearn.feature_extraction.text import CountVectorizer
from valops.data import Dataset
from valops.models.model import LocalModel


@dataclass
class TopicResult:
    topics: List[int]
    probabilities: np.ndarray
    topic_info: Optional[Dict[str, Any]] = None


class BertTopicWrapper(LocalModel):
    def __init__(
        self,
        model_id: str,
        vectorizer_params: Optional[Dict[str, Any]] = None,
        embedding_model: Optional[Any] = None,
    ):
        """
        Initialize the BertTopicWrapper with optional vectorizer and embedding model.
        """
        super().__init__(model_id)
        self.vectorizer_params = vectorizer_params or {}
        self.embedding_model = embedding_model or "all-MiniLM-L6-v2"  # Default embedding model
        self.model = BERTopic(
            embedding_model=self.embedding_model,
            vectorizer_model=CountVectorizer(**self.vectorizer_params),
        )

    def fit(self, documents: List[str]) -> TopicResult:
        """
        Train the BERTopic model on a list of documents.
        """
        print("Fitting BERTopic model...")
        topics, probabilities = self.model.fit_transform(documents)
        topic_info = self.model.get_topic_info()
        return TopicResult(
            topics=topics,
            probabilities=probabilities,
            topic_info=topic_info.to_dict(),
        )

    def predict(self, documents: List[str]) -> TopicResult:
        """
        Predict topics for new documents.
        """
        print("Predicting topics...")
        topics, probabilities = self.model.transform(documents)
        return TopicResult(
            topics=topics,
            probabilities=probabilities,
        )

    def get_topic(self, topic_id: int) -> Optional[Dict[str, Any]]:
        """
        Get details of a specific topic by its ID.
        """
        print(f"Retrieving details for topic {topic_id}...")
        topic = self.model.get_topic(topic_id)
        return {"topic_id": topic_id, "words": topic} if topic else None

    def get_embeddings(self, documents: List[str]) -> np.ndarray:
        """
        Generate embeddings for a list of documents.
        """
        print("Generating embeddings using BERTopic's embedding model...")
        embeddings = self.model.embedding_model.transform(documents)
        return embeddings

    def fine_tune(
        self,
        documents: List[str],
        custom_embeddings: Optional[np.ndarray] = None,
        labels: Optional[List[int]] = None,
        epochs: int = 1,
        parameters: Optional[Dict[str, Any]] = None,
    ):
        """
        Fine-tune BERTopic by updating its embeddings and optionally retraining the topic model.
        """
        print("Fine-tuning BERTopic model...")
        if custom_embeddings is not None:
            self.model.update_topics(documents, embeddings=custom_embeddings)
        elif labels:
            self.model.set_labels(labels)
        else:
            print("No custom embeddings or labels provided for fine-tuning.")

    def reduce_topics(self, documents: List[str], nr_topics: int) -> TopicResult:
        """
        Reduce the number of topics in the BERTopic model.
        """
        print(f"Reducing topics to {nr_topics}...")
        self.model.reduce_topics(nr_topics=nr_topics)
        topics, probabilities = self.model.transform(documents)
        return TopicResult(
            topics=topics,
            probabilities=probabilities,
            topic_info=self.model.get_topic_info().to_dict(),
        )

    def save(self, path: str):
        """
        Save the BERTopic model to disk.
        """
        print(f"Saving model to {path}...")
        self.model.save(path)

    def load(self, path: str):
        """
        Load the BERTopic model from disk.
        """
        print(f"Loading model from {path}...")
        self.model = BERTopic.load(path)
